<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>CS489 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso-light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="../katex/katex.min.js" type="text/javascript"></script>
  <link rel="stylesheet" href="../katex/katex.min.css" />
  <script type="text/javascript">
  window.onload = function() {
    document.getElementsByClassName("status-banner")[0].style.display = "block";
    setTimeout(function() {
      renderMathElements(document.getElementsByClassName("math"));
      document.getElementsByClassName("status-banner")[0].style.display = "none";
    }, 50); // delay to allow status banner to show
  }

  function renderMathElements(mathElements) {
    var mathOptions = {
      macros: {
        "\\set": "\\left\\{ #1 \\right\\}",
        "\\tup": "\\left\\langle #1 \\right\\rangle",
        "\\abs": "\\left\\lvert #1 \\right\\rvert",
        "\\floor": "\\left\\lfloor #1 \\right\\rfloor",
        "\\ceil": "\\left\\lceil#1 \\right\\rceil",
        "\\mb": "\\mathbb{#1}",
        "\\rem": "\\operatorname{rem}",
        "\\ord": "\\operatorname{ord}",
        "\\sign": "\\operatorname{sign}",
        "\\imag": "\\bm{i}",
        "\\dee": "\\mathop{}\\!\\mathrm{d}",
        "\\lH": "\\overset{\\text{l'H}}{=}",
        "\\evalat": "\\left.\\left(#1\\right)\\right|",
        "\\sech": "\\operatorname{sech}",
        "\\spn": "\\operatorname{Span}",
        "\\proj": "\\operatorname{proj}",
        "\\prp": "\\operatorname{perp}",
        "\\refl": "\\operatorname{refl}",
        "\\magn": "\\left\\lVert #1 \\right\\rVert",
        "\\rank": "\\operatorname{rank}",
        "\\sys": "\\left[ #1 \\mid #2\\space \\right]",
        "\\range": "\\operatorname{Range}",
        "\\adj": "\\operatorname{adj}",
        "\\cof": "\\operatorname{cof}",
        "\\coord": "{\\left\\lbrack #1 \\right\\rbrack}_{#2}",
        "\\diag": "\\operatorname{diag}",
        "\\formlp": "\\operatorname{Form}(\\mathcal{L}^P)",

        // not yet available in KaTeX
        "\\operatorname": "\\mathop{\\text{#1}}\\nolimits", //wip: spacing is slightly off
        "\\not": "\\rlap{\\kern{7.5mu}/}", //wip: slash angle is slightly off
        "\\bm": "\\mathbf", //wip: should be italic, but isn't
      },
      throwOnError: false,
    };
    for (var i=0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      katex.render(texText.data, mathElements[i], mathOptions);
    }
  }
  </script>
</head>
<body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/resume.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="https://www.linkedin.com/in/uberi/" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:me@anthonyz.ca" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="https://twitter.com/anthony926535" class="contact">twitter</a></li>
    <span class="divider"></span>
    <li><a href="https://keybase.io/uberi" class="info">public key</a></li>
  </ul>
<h1 id="cs489">CS489</h1>
<p>Special Topics in Computer Science - Introduction to Machine Learning.</p>
<pre><code>Yaoliang Yu
Section 001
Email: yaoliang.yu@uwaterloo.ca
Website: http://cs.uwaterloo.ca/~y328yu/mycourses/489
Office Hours: Tuesdays/Thursdays 2:40pm-3:40pm in DC-3617
Tuesdays/Thursdays 4:00pm-5:20pm</code></pre>
<h1 id="section">7/9/17</h1>
<p>Course is potentially going to be collaboration between professor and Focal Systems - guest lectures by deep learning engineers from Focal and assignments from real-world systems. Contact agastya@focal.systems for questions and comments.</p>
<p>Course questions on Piazza, content on LEARN. Course will use MATLAB, Python, or Julia, and requires CS341 concepts.</p>
<p>No required textbooks. 5 semi-weekly assignments worth 50% total, submittable via LEARN, remaining 50% from an open book final exam. There's also a 5% bonus project, consisting of a 1 page proposal and 8 page report on a machine-learning-related project. ;wip: conssider one for robotics control</p>
<p>Machine learning is about giving computers the ability to learn things that they aren't explicitly programmed to do. More specifically, for a machine to <strong>learn</strong> is to, as experience <span class="math inline">E</span> increases, improve a performance measure <span class="math inline">P</span> for some class of tasks <span class="math inline">T</span>. Essentially, a program learns if it <strong>gets better at solving a problem as it gains more experience</strong>.</p>
<p>Machine learning falls into three categories:</p>
<ul>
<li>Supervised learning: classification/regression/ranking - there's a source of truth that the machine can use to determine the true answer for at least some of the problem instances.
<ul>
<li>Example: the Not Hotdog app - images labelled hotdogs/not-hotdogs are used to train the model, which is then used to make predictions about new images.</li>
<li>Given a training set of pairs <span class="math inline">\tup{x, y}</span>, find a function <span class="math inline">f: X \to Y</span> such that <span class="math inline">f(x)</span> has good performance on values of <span class="math inline">x</span> that haven't been seen in the training set.</li>
<li>We don't actually care that much about performance in the training set - too-high performance in the training set is overfitting</li>
</ul></li>
<li>Reinforcement learning: control/pricing/gaming - there's no explicit source of truth, but doing something gives feedback, like how good the previous output was.
<ul>
<li>Example: AlphaGo uses a reinforcement learning model to guide monte-carlo tree search - wins give positive feedback, losses give negative feedback.</li>
</ul></li>
<li>Unsupervised learning: clustering - there's no explicit source of truth.
<ul>
<li>Example: Google Youtube clustering 9-layer network from 2012 was trained to cluster objects, and managed to learn to detect faces by itself.</li>
</ul></li>
</ul>
<p>Modern ML research focuses on representation of data (e.g., feature engineering), interpretation of results, generalizing models to different domains (e.g., applying image classifiers to video), time/space complexity, learning efficiency (how many samples do we need? how big does the training set need to be?), and real-world applications.</p>
<p>New notation: <span class="math inline">A_i</span> is the <span class="math inline">i</span>-th 1-indexed row of the matrix <span class="math inline">A</span>, and <span class="math inline">A_{:j}</span> is the <span class="math inline">j</span>-th 1-indexed column of the matrix <span class="math inline">A</span>.</p>
<p>New notation: <span class="math inline">\sign x = \begin{cases} 1 &amp;\text{if } x &gt; 0 \\ -1 &amp;\text{if } x &lt; 0 \\ \text{undefined} &amp;\text{if } x = 0 \end{cases}</span>.</p>
<p>New notation: derivative of a function is <span class="math inline">Df(x) = \lim_{\delta \to 0} \frac{f(x + \delta) - f(x)}{\delta}</span>.</p>
<p>New notation: <span class="math inline">\min_{a: f(a), b: g(b), \ldots} f(a, b, c, \ldots)</span> is the minimum value of <span class="math inline">f(a, b, c, \ldots)</span> such that <span class="math inline">f(a), g(b), \ldots</span> are all true. The <span class="math inline">a: f(a)</span> part might also be written as just <span class="math inline">a</span> if there's no constraints.</p>
<p>New notation: <span class="math inline">\argmin_{a: f(a), b: g(b), \ldots} f(a, b, c, \ldots)</span> is the values of <span class="math inline">a, b, c, \ldots</span> such that <span class="math inline">f(a, b, c, \ldots)</span> is minimised and <span class="math inline">f(a), g(b), \ldots</span> are all true. The <span class="math inline">a: f(a)</span> part might also be written as just <span class="math inline">a</span> if there's no constraints.</p>
<h1 id="section-1">12/9/17</h1>
<p>Consider the problem of filtering out spam emails. The training set would be a set <span class="math inline">X</span> of emails (e.g., a vector where each dimension represents a feature, like whether word <span class="math inline">i</span> appears in the email) and a set <span class="math inline">Y</span> representing the spamminess of those emails (e.g., real number between -1 and 1). One of the most important parts of this task is making sure we have a good representation for features in our emails. In a bag of words model, for example, we might make <span class="math inline">X</span> a 10000-dimensional vector where each element represents whether one of 10000 words appears in the email's subject.</p>
<p>In <strong>batch learning</strong>, we care about performance on the testing set <span class="math inline">X&#39;</span>, and the training set is just the means by which we get there, by performing statistics on <span class="math inline">X</span> and assuming things about <span class="math inline">X&#39;</span>. In <strong>online learning</strong>, data is received in a streaming fashion - we need to product the value of <span class="math inline">y</span> without knowing its true value.</p>
<p>In this course, we'll use <span class="math inline">&lt;a, b&gt;</span> to represent the inner product <span class="math inline">a \cdot b = a^T b</span>. Also, <span class="math inline">\sign(x)</span> is 1 when <span class="math inline">x &gt; 0</span>, -1 when <span class="math inline">x &lt; 0</span>, and undefined when <span class="math inline">x = 0</span> (some other courses will instead define it to be 0).</p>
<h2 id="perceptrons">Perceptrons</h2>
<p>The perceptron is a machine learning model based on a highly simplified model of a neuron. It takes in activation from neighboring neurons, takes their weighted sum, and then applies the activation function to them, the <span class="math inline">\sign</span> function, which is the neuron's output. We'll study Rosenblatt's original design from 1958, along with several additions and improvements made since then.</p>
<p>Perceptrons are used for <strong>binary classification problems</strong>. We are given a training set <span class="math inline">\set{\tup{\vec x_1, y_1}, \tup{\vec x_2, y_2}, \ldots}</span> and a testing set <span class="math inline">\set{\vec t_1, \vec t_2, \ldots}</span> where <span class="math inline">\vec x_i, \vec t_i</span> are feature vectors, and <span class="math inline">y_i</span> is the binary <strong>category</strong>, either -1 or 1. Using the training set, we want to train the perceptron to determine the category <span class="math inline">y_i</span> for each <span class="math inline">\vec t_i</span>.</p>
<p>A perceptron is simply <span class="math inline">y = \sign(\vec w \cdot \vec x + b)</span>, where <span class="math inline">\vec w</span> is the perceptron's <strong>weights vector</strong>, <span class="math inline">b</span> is the perceptron's <strong>bias</strong>, <span class="math inline">\vec x</span> is the <strong>input</strong>, and <span class="math inline">y \in \set{-1, 1}</span> is the <strong>prediction</strong>. Note that <span class="math inline">\vec w + b</span> should be a <strong>hyperplane</strong> separating the positive values of <span class="math inline">y_i</span> from the negative values of <span class="math inline">y_i</span>, and the sign of <span class="math inline">\vec w \cdot \vec x + b</span> determines which side of the hyperplace the point <span class="math inline">\vec x</span> is on (the positive predictions side, or the negative predictions side). For now, let's assume that for the training set, there exists a hyperplane that separates all of the positives from all of the negatives - that the data is <strong>separable</strong>.</p>
<p>Now we'll try to simplify the perceptron formula to make it easier to work with. First, let's get rid of the <span class="math inline">\sign</span> by multiplying both sides of the perceptron formula by <span class="math inline">y</span>: <span class="math inline">y^2 = y \sign(\vec w \cdot \vec x + b)</span>, and since <span class="math inline">y</span> is either -1 or 1, <span class="math inline">y^2 = 1</span>, so <span class="math inline">y \sign(\vec w \cdot \vec x + b) = 1</span>, or in other words, <span class="math inline">y (\vec w \cdot \vec x + b) &gt; 0</span>. Expand to get <span class="math inline">\vec w \cdot (y\vec x) + by &gt; 0</span></p>
<p>Let <span class="math inline">\vec w&#39; = \begin{bmatrix} \vec w \\ b \end{bmatrix}</span> and <span class="math inline">a = \begin{bmatrix} y \vec x \\ y \end{bmatrix}</span> - we've chosen these definitions specifically so that <span class="math inline">\vec w \cdot (y\vec x) + by &gt; 0</span> is equivalent to <span class="math inline">a \cdot w&#39; &gt; 0</span>, and so that the value of <span class="math inline">\vec w&#39;</span> represents the perceptron parameters exactly.</p>
<p>When training the perceptron, our goal is to fit the hyperplane to our training set. That means we'll want to make perceptron predictions in bulk, so it would be nice to be able to represent that in a compact way. To do this, we'll let <span class="math inline">A = \begin{bmatrix} \vec a_1 &amp; \vec a_2 &amp; \ldots \end{bmatrix}</span>, where <span class="math inline">\vec a_i = \begin{bmatrix} y_i \vec x_i \\ y_i \end{bmatrix}</span> - columns of <span class="math inline">A</span> are values of <span class="math inline">\vec a</span> corresponding to each value of <span class="math inline">\vec x_i</span>. Written out fully, that's <span class="math inline">A = \begin{bmatrix} y_1 \vec x_1 &amp; y_2 \vec x_2 &amp; \ldots \\ y_1 &amp; y_2 &amp; \ldots \end{bmatrix}</span>.</p>
<p>Clearly, <span class="math inline">A^T \vec w&#39; &gt; 0</span> is equivalent to <span class="math inline">\forall \vec x_i, \sign(\vec w&#39; \cdot \vec x_i + b) = y</span>. We've now simplified the perceptron problem down to a single matrix multiplication and a comparison! Now, <span class="math inline">\vec w&#39;</span> contains all the perceptron parameters, and the columns of <span class="math inline">A</span> are the data points (each with a trailing 1 element), premultiplied by the label.</p>
<p>Now the problem becomes: given premultiplied data in a matrix <span class="math inline">A</span>, find <span class="math inline">\vec w&#39;</span> such that <span class="math inline">A^T \vec w&#39; &gt; 0</span>. The <strong>perceptron training algorithm</strong> does this, and works as follows: repeatedly choose a column <span class="math inline">\vec a_i</span> of <span class="math inline">A</span>, and if <span class="math inline">\vec a_i \cdot \vec w&#39; \le 0</span>, change <span class="math inline">\vec w&#39;</span> by adding <span class="math inline">\vec a_i</span> to it. Stop when <span class="math inline">\vec a_i \cdot \vec w&#39; &gt; 0</span> for all <span class="math inline">\vec a_i</span> in <span class="math inline">A</span>, or when we reach an iteration/passes limit.</p>
<p>Why do we correct the weights when <span class="math inline">\vec a_i \cdot \vec w&#39; \le 0</span> by adding <span class="math inline">\vec a_i</span> to <span class="math inline">\vec w&#39;</span>? Well, the next time we choose the <span class="math inline">\vec a_i</span> column, we'll get <span class="math inline">\vec a_i \cdot (\vec w&#39; + \vec a_i) = \vec a_i \cdot \vec w&#39; + \magn{\vec a_i}^2</span>. Since <span class="math inline">\magn{\vec a_i}^2 &gt; 0</span>, <span class="math inline">\vec a_i \cdot (\vec w&#39; + \vec a_i) &gt; \vec a_i \cdot \vec w&#39;</span>, so <span class="math inline">\vec a_i \cdot (\vec w&#39; + \vec a_i)</span> is closer to being positive.</p>
<p>(Python implementation not included, since this is a question in assignment 1)</p>
<p>After training, we can make predictions for any given input <span class="math inline">\vec x</span> with the usual formula, <span class="math inline">y = \sign\left(\vec w&#39; \cdot \begin{bmatrix} \vec x \\ 1 \end{bmatrix}\right)</span>.</p>
<p>This algorithm is very simple to implement, yet works quite well in practice. Also, the fact that its formula is a linear combination is interesting. If we look at the weights, we notice that large positive weights mean that the corresponding feature strongly suggests that the prediction should be positive, whereas large negative weights strongly suggest that the prediction should be negative.</p>
<p>How well does a perceptron converge when running the training algorithm described above? <strong>Block's perceptron convergence theorem</strong> gives us an idea. If <span class="math inline">A</span> is separable (i.e., a hyperplane exists that separates positive cateogry points from negative category points), then <span class="math inline">\vec w&#39;</span> will converge to some <span class="math inline">\vec w^*</span>. If every column of <span class="math inline">A</span> is selected indefinitely often, then <span class="math inline">A^T \vec w^* &gt; 0</span>. Furthermore, if <span class="math inline">\vec w&#39; = \vec 0</span> initially, then the perceptron converges after at most <span class="math inline">(R / \gamma)^2</span> iterations, where <span class="math inline">R = \max\set{\magn{a_1}, \magn{a_2}, \ldots}</span> and <span class="math inline">\gamma = \max\set{\min\set{\vec w \cdot \vec a_1, \vec w \cdot \vec a_2, \ldots} : \magn{\vec w} \le 1}</span> (the margin - the minimum distance between the convex hull of the positive points and the negative points). Essentially, the margin represents the distance between the &quot;hardest&quot; two datapoints to classify.</p>
<p>Note that these values of <span class="math inline">R</span> and <span class="math inline">\gamma</span> are purely functions of the dataset, and that they don't directly depend on the size of <span class="math inline">A</span> and the number of dimensions <span class="math inline">d</span>. In other words, the number of mistakes the perceptron makes would be independent of the dataset size and number of dimensions! The larger the margin is, the faster the perceptron converges. Block's perceptron convergence theorem gives us a worst case bound, but in many practical situations the perceptron will perform a lot better.</p>
<p>Also, the perceptron stops at an arbitrary linear separator that correctly separates the points, not necessarily the one that most cleanly separates the positive and negative points (with the largest possible minimum distance from the hyperplane to positive/negative predictions). In fact, the resulting hyperplane will even depend on the order we feed in the data. We can use support vector machines instead to find that hyperplane (which also happens to be unique for each dataset!). This is the main disadvantage of perceptrons - they might only barely separate the training data, so they're less robust to unseen data than those that find a linear separator with a larger margin.</p>
<p>If the data is <strong>not separable</strong>, Block's perceptron convergence theorem doesn't apply anymore. The <strong>perceptron boundedness theorem</strong> says that convergence is only guaranteed if such a hyperplane exists, but if it doesn't, then the iterations are still bounded, because the perceptron's state will start cycling after a certain number of iterations. In practice, this means we would specify a time or iteration limit when doing training, or when the training/validation error stops changing, or even if weights stop changing much when using diminishing step sizes.</p>
<p>If we end up with non-separable data, we might want to find a better feature representation, use a deeper model, or use a <strong>soft margin</strong> - instead of a hyperplane that perfectly separates positive/negative values of <span class="math inline">y</span>, we can allow a few mistakes.</p>
<p>There are many ways to extend perceptrons to classify things into more than two categories (positive/negative). One way is <strong>one vs. all</strong>, where we have one perceptron per category, perceptron with highest activation level wins - <span class="math inline">\max_c(w_c \cdot x)</span>. The issue with this is that it's imbalanced - each perceptron has to give negative predictions far more often than positive ones, since it only gives positive prediction for its own category and otherwise must give a negative prediction. Another is <strong>one vs. one</strong>, where we have one perceptron for every pair of categories, where a positive prediction means the datapoint is in the first category and negative means the other category, and then take a vote to find the most commonly predicted category as the final answer.</p>
<p>An example of applying perceptrons online is pricing - selling a product to the user at a price <span class="math inline">y</span>, and updating weights if the price is too high and the user doesn't buy the product.</p>
<h1 id="section-2">14/9/17</h1>
<p>Assignment 1 now available, due in two weeks.</p>
<p>A <strong>pass</strong> is a run through all of the training data - 100 passes means we go through the training data 100 times. An <strong>iteration</strong> is a run through a single data point in our training data.</p>
<h2 id="linear-regression">Linear Regression</h2>
<p>Consider a scatter plot of house market value vs. square footage. We'd expect that these two are pretty well correlated. A linear regression over these two variables can be used to give us a line of best fit.</p>
<p>Regression problems are about fitting models to match datasets as closely as possible. Linear regression problems try to fit linear models to datasets. When we're doing regression problems, we have to consider whether to use linear/nonlinear models, and whether we'll be using it to interpolate or extrapolate (choosing the perfect model is much more important for extrapolation)</p>
<p>Formally, a regression problem is: find <span class="math inline">f(\vec x) \approxeq \vec y</span> given <span class="math inline">\vec x</span> (the <strong>feature vector</strong> a real vector) and <span class="math inline">y</span> (the <strong>response value</strong>, a real number). The hard part of this is that <span class="math inline">\vec x</span> and <span class="math inline">y</span> are drawn from unknown distributions, which makes it hard to interpolate/extrapolate. Additionally, we need a way to express how much error there is in our model predictions - a <strong>loss function</strong>.</p>
<p>One family of regression algorithms is <strong>risk minimizers</strong> (expected loss minimizers): algorithms that try to find <span class="math inline">f</span> such that <span class="math inline">\min_{f: \vec x \to y} E[L(f(\vec x), y)]</span>, where <span class="math inline">L</span> is the loss function.</p>
<p>A common loss function is <strong>least squares</strong>: <span class="math inline">\min_{f: \vec x \to y} E[\magn{f(\vec x) - y}^2]</span>. The correct loss function for a given situation is often hard to determine, so we use one that's simple and efficient to compute - least squares works well enough for most situations. Additionally, of all the minimizers of $_W _F, <span class="math inline">W = A^+ CB^+</span>$ is the one with the smallest F-norm, where <span class="math inline">A^+</span> is the pseudo-inverse of <span class="math inline">A</span> (Sondermann '86, Yu &amp; Shuurmans '11) - this is mostly a theoretical result, but gives us another good reason to use least squares loss.</p>
<p>Clearly, <span class="math inline">E[\magn{f(\vec x) - y}^2] = E[\magn{f(\vec x) - E(y \mid \vec x)}^2] + E[\magn{E(y \mid \vec x) - y}^2]</span>. Note that the second term doesn't really depend on <span class="math inline">f</span> - it's the <strong>inherent noise variance</strong>, the noise that we can't get rid of no matter how good our regression function is. Also, the first term gives us the problem in a much simpler form: we want to find an <span class="math inline">f(\vec x)</span> that approximates <span class="math inline">E(y \mid \vec x)</span> well, to make this term smaller.</p>
<p>One way to make this optimization process easier is to assume that <span class="math inline">f(\vec x)</span> is linear, so <span class="math inline">f(\vec x) = E(\vec y \mid \vec x) = A \vec x + \vec b</span> for some matrix <span class="math inline">A</span>. If we make this assumption, then with risk minimization we're trying to find <span class="math inline">\min_{f: \vec x \to \vec y} E[A \vec x + \vec b - \vec y]</span>. We can't minimize this directly because we don't know the true distribution of the variables, but using the law of large numbers, <span class="math inline">\frac 1 n \sum Z_i = E(Z)</span> for any <span class="math inline">Z = \set{Z_1, Z_2, \ldots}</span>. So if we assume the model is linear, and the sample is large, then the risk minimization can be approximated by <span class="math inline">\min_{\vec a, \vec b} \frac 1 n \sum \magn{A \vec x + \vec b - \vec y}^2</span> (this approximation is called the <strong>empirical risk</strong>).</p>
<p>Let's simplify the <span class="math inline">\min_{\vec a, \vec b} \frac 1 n \sum \magn{A \vec x + \vec b - \vec y}^2</span> approximation, using something very similar to what we did for perceptrons. First, let's define <span class="math inline">W = \begin{bmatrix} A^T \\ {\vec b}^T \end{bmatrix}</span> and <span class="math inline">\vec x&#39; = \begin{bmatrix} \vec x \\ 1 \end{bmatrix}</span>. Now we have <span class="math inline">\min_W \frac 1 n \sum \magn{W^T \vec x&#39; - \vec y}^2</span>, which is slightly shorter/cleaner.</p>
<p>Let <span class="math inline">\vec x_i</span> be the <span class="math inline">i</span>th value of <span class="math inline">\vec x</span> in our training set. Just like for the perceptrons simplifications above, we also want to include all of the training set data points in a single expression, to make our minimization problem simpler. To do this, let <span class="math inline">X = \begin{bmatrix} {\vec x_1&#39;}^T \\ {\vec x_2&#39;}^T \\ \vdots \end{bmatrix}, Y = \begin{bmatrix} {\vec y_1}^T \\ {\vec y_2}^T \\ \vdots \end{bmatrix}</span>. Now, we can write this as <span class="math inline">\min_W \magn{XW - Y}_F^2</span> where <span class="math inline">\magn{A}_F = \sum_{i, j} A_ij</span> is the <strong>Frobenius norm</strong> - each element simply gets squared and the squares are all summed together to get the result, like the Euclidean norm, but extended for any matrix.</p>
<p>The <strong>least squares problem</strong> is now writeable as <span class="math inline">\min_W \magn{XW - Y}_F^2</span>, and we're minimizing the <strong>sum of square residuals</strong> <span class="math inline">XW - Y</span> (sum of square distances between the predicted values and true values). Here, <span class="math inline">Y</span> is a matrix with columns as the true responses, and the residuals are the distances between each true response in <span class="math inline">Y</span> and the point that the hyperplane would predict given <span class="math inline">X</span>.</p>
<p>Note that the Frobenius norm can be defined as: <span class="math inline">\magn{A}_F^2 = \trace{A^T A}</span>. Additionally, the following are identities: <span class="math inline">\trace(A + B) = \trace(A) + \trace(B)</span>, <span class="math inline">\trace(AB) = \trace(BA)</span>, <span class="math inline">\trace(A) = \trace(A^T)</span>, and <span class="math inline">\trace(cA) = c \trace(A)</span>.</p>
<p>Therefore, <span class="math inline">\magn{XW - Y}_F^2 = \trace((XW - Y)^T (XW - Y)) = \trace((W^T X^T - Y^T) (XW - Y)) = \trace(W^T X^T X W - Y^T X W - W^T X^T Y + Y^T Y) = \trace(W^T X^T X W) - \trace((Y^T X W)^T) - \trace(W^T X^T Y) + \trace(Y^T Y) = \trace(W^T X^T X W) - \trace(W^T X^T Y) - \trace(W^T X^T Y) + \trace(Y^T Y) = \trace(W^T X^T X W - 2 W^T X^T Y + Y^T Y)</span>. Clearly, this is a quadratic equation with respect to <span class="math inline">W</span>, and we want to find its minimum.</p>
<p>Consider <span class="math inline">\min_x f(x)</span>. Fermat's theorem says that at the minimum <span class="math inline">x</span>, the derivative of <span class="math inline">f(x)</span> must be 0. Consider a general quadratic function <span class="math inline">f(x) = \vec x^T A \vec x + \vec x^T \vec b + c</span>. The derivative is then <span class="math inline">\frac{\dee f(x)}{\dee x} = (A + A^T)\vec x + \vec b</span>.</p>
<p>Note that <span class="math inline">\magn{XW - Y}_F^2 = W^T(X^T X) W - 2W^T X^T Y + Y^T Y</span> (a quadratic equation), and if set the derivative of this to 0 and solve we get <span class="math inline">X^T X W = X^T Y</span> as a solution, which is just a linear system - we have <span class="math inline">X</span> and <span class="math inline">Y</span>, so we can solve for <span class="math inline">W</span>. Note that <span class="math inline">X^T X</span> might be invertible, but we should still never solve for <span class="math inline">W</span> by using <span class="math inline">W = (X^T X)^{-1} X^T Y</span>, since this involves solving <span class="math inline">n</span> linear systems, whereas we can solve it by solving only 1 linear system (in practice, we should almost never actually compute matrix inverses).</p>
<p>Once we have <span class="math inline">W</span>, we can make predictions for any given <span class="math inline">X</span> using <span class="math inline">\hat Y = XW</span>, or evaluate those predictions with <span class="math inline">(Y - \hat Y)^2</span>. We can also evaluate using a different loss function, a technique often used in calibration theory.</p>
<p>Linear regression is disproportionally affected by large outliers. To mitigate this, we sometimes use Huber loss, which is linear for large differences and quadratic for smaller ones, where &quot;larger&quot; and &quot;smaller&quot; are defined by a threshold <span class="math inline">\delta</span>. This ensures overly large outliers don't impact the result too much. Huber's loss function is defined as <span class="math inline">H(\hat y, y) = \begin{cases} \frac 1 2 (\hat y - y)^2 &amp;\text{if } \abs{\hat y - y} \le \delta \\ \delta(\abs{\hat y - y} - \frac{\delta}{2}) &amp;\text{otherwise} \end{cases}</span>.</p>
<p>Ill-posed problems are those in which small changes in the input to linear models results in huge differences in the output. To handle this sort of regression task, we can use <strong>Tiknohov regularization</strong>. To do this, we just add a term to the formula: <span class="math inline">\min_W \magn{XW - Y}_F^2 + \lambda \magn{W}_F^2</span>, or equivlaently, <span class="math inline">(X^T X + \lambda I)W = X^T Y</span>. A small positive lambda ensures that instead of a small change in the input resulting in a huge difference in the output, it would result in a difference proportional to <span class="math inline">\frac{1}{\lambda}</span> instead. Another way to handle ill-posed problems is to use data augmentation - essentially, adding more data points to make the data appear more regular.</p>
<p>How do we choose hyperparameters like <span class="math inline">\lambda</span> for Tiknohov regularization? We have a training set (for model training), testing set (which we don't see until the end), and sometimes a small validation set (for tuning parameters), and on the training set, we can apply <strong>cross-validation</strong>. Suppose we have <span class="math inline">k</span> different values of <span class="math inline">\lambda</span> we want to consider. First, we split the training set into <span class="math inline">n</span> chunks, and evaluate the model for each different value of <span class="math inline">\lambda</span> for each of the chunks - a total of <span class="math inline">kn</span> evaluations. The overall performance score for each value of <span class="math inline">\lambda</span> is then the sum of the performance scores for that value of <span class="math inline">\lambda</span> within each chunk. We can then choose the value of <span class="math inline">\lambda</span> with the greatest overall performance score.</p>
<h1 id="section-3">19/9/17</h1>
<p>Guest lecture by Francois from Focal Systems (francois@focal.systems).</p>
<p>Almost any ML problem falls into regression or classification.</p>
<p>For linear regression, we're assuming that the response variable <span class="math inline">y</span> is approximated by <span class="math inline">\vec \theta \cdot \vec x + N(0, \sigma)</span>, where <span class="math inline">N(0, \sigma)</span> is a normal distribution centered around 0 with standard deviation <span class="math inline">\sigma</span>. Further overview of some real-world details in implementing linear regression.</p>
<p>Though linear regression is simplistic, it turns out that it works very well in practice, since more complex models require more advanced ways to do regularization and get decent weight vectors. Tools like SVM are used a lot in the real world to model real phenomena, even when they aren't necessarily linear, because it works well enough for most purposes.</p>
<p>Most modern ML problems use SGD - stochastic gradient descent.</p>
<p>A Bernoulli model predicts <span class="math inline">y = P(Y_1 = y_1, \ldots, Y_n = y_n \mid X_1 = x_1, \ldots, X_n = x_n)</span>. If we assume that the distribution of the variables are a Bernoulli distribution, so they're independent, we can then write this as <span class="math inline">y = \prod P(Y_i = y_i \mid X_i = x_i) = \prod p(x_i; w)^{y_i} (1 - p(x_i; w))</span> ;wip: get the formula for this</p>
<p>Logistic regression tries to predict the value of <span class="math inline">0 \le y \le 1</span> given <span class="math inline">\vec x</span> by fitting the formula <span class="math inline">\frac 1 {1 + \exp(\vec w \cdot x)}</span>, where <span class="math inline">\vec w</span> is the thing that we're trying to fit.</p>
<p>We use a sigmoid rather than, say, a step function, because the gradient doesn't have any signal - if we differentiate it, the derivative is just 0 everywhere, so gradient descent wouldn't be able to get closer to the solution at every step. Instead, the sigmoid formula has a gentle curve, so its derivative is more suitable for performing gradient descent on.</p>
<p>Our loss function is then <span class="math inline">f(y&#39;, y) = \ln(y&#39;) * y + \ln(1 - y&#39;) (1 - y)</span>, where <span class="math inline">y&#39;</span> is the model's prediction and <span class="math inline">y</span> is the true value. ;wip: why???</p>
<p>Tensorflow example, implementing logistic regression using the built in gradient descent optimizer to minimize the loss function. When doing gradient descent, we want the largest learning rate that still converges.</p>
<div class="status-banner" style="display: none; position: fixed; bottom: 0; left: 0; right: 0; text-align: center;">
    <div style="display: inline-block; padding: 0.8em 2em 0.5em 2em; background: black; color: white; font-size: 2em;">
        Rendering <svg xmlns="http://www.w3.org/2000/svg" height="1.4em" viewbox="0 0 1200 500" style="vertical-align: text-bottom"><title>LaTeX logo</title><g transform="matrix(45 0 0 45 40 40)" fill="white"><path d="M5.5 4.4C5.5 4.4 5.2 4.4 5.2 4.4 5.1 5.4 5 6.7 3.2 6.7 3.2 6.7 2.4 6.7 2.4 6.7 1.9 6.7 1.9 6.6 1.9 6.3 1.9 6.3 1.9 1 1.9 1 1.9 0.6 1.9 0.5 2.9 0.5 2.9 0.5 3.2 0.5 3.2 0.5 3.2 0.5 3.2 0.2 3.2 0.2 2.8 0.2 1.9 0.2 1.5 0.2 1.1 0.2 0.3 0.2 0 0.2 0 0.2 0 0.5 0 0.5 0 0.5 0.2 0.5 0.2 0.5 1 0.5 1 0.6 1 0.9 1 0.9 1 6.2 1 6.2 1 6.6 1 6.7 0.2 6.7 0.2 6.7 0 6.7 0 6.7 0 6.7 0 7 0 7 0 7 5.2 7 5.2 7 5.2 7 5.5 4.4 5.5 4.4z"/><path d="M5.3 0.2C5.3 0 5.2 0 5.1 0 5 0 4.9 0 4.9 0.2 4.9 0.2 3.3 4.2 3.3 4.2 3.2 4.4 3.1 4.7 2.5 4.7 2.5 4.7 2.5 5 2.5 5 2.5 5 4 5 4 5 4 5 4 4.7 4 4.7 3.7 4.7 3.5 4.6 3.5 4.4 3.5 4.3 3.5 4.3 3.6 4.2 3.6 4.2 3.9 3.4 3.9 3.4 3.9 3.4 5.9 3.4 5.9 3.4 5.9 3.4 6.3 4.4 6.3 4.4 6.3 4.4 6.3 4.5 6.3 4.5 6.3 4.7 5.9 4.7 5.8 4.7 5.8 4.7 5.8 5 5.8 5 5.8 5 7.7 5 7.7 5 7.7 5 7.7 4.7 7.7 4.7 7.7 4.7 7.6 4.7 7.6 4.7 7.1 4.7 7.1 4.7 7 4.5 7 4.5 5.3 0.2 5.3 0.2zM4.9 0.9C4.9 0.9 5.8 3.1 5.8 3.1 5.8 3.1 4 3.1 4 3.1 4 3.1 4.9 0.9 4.9 0.9z"/><path d="M13.3 0.2C13.3 0.2 7.2 0.2 7.2 0.2 7.2 0.2 7 2.5 7 2.5 7 2.5 7.3 2.5 7.3 2.5 7.4 0.9 7.6 0.5 9.1 0.5 9.3 0.5 9.5 0.5 9.6 0.6 9.8 0.6 9.8 0.7 9.8 0.9 9.8 0.9 9.8 6.2 9.8 6.2 9.8 6.5 9.8 6.7 8.8 6.7 8.8 6.7 8.4 6.7 8.4 6.7 8.4 6.7 8.4 7 8.4 7 8.8 6.9 9.8 6.9 10.3 6.9 10.7 6.9 11.7 6.9 12.2 7 12.2 7 12.2 6.7 12.2 6.7 12.2 6.7 11.8 6.7 11.8 6.7 10.7 6.7 10.7 6.5 10.7 6.2 10.7 6.2 10.7 0.9 10.7 0.9 10.7 0.7 10.7 0.6 10.9 0.6 11 0.5 11.3 0.5 11.5 0.5 13 0.5 13.1 0.9 13.2 2.5 13.2 2.5 13.5 2.5 13.5 2.5 13.5 2.5 13.3 0.2 13.3 0.2z"/><path d="M18.7 6.7C18.7 6.7 18.4 6.7 18.4 6.7 18.2 8.2 17.9 8.9 16.2 8.9 16.2 8.9 14.9 8.9 14.9 8.9 14.4 8.9 14.4 8.8 14.4 8.5 14.4 8.5 14.4 5.9 14.4 5.9 14.4 5.9 15.3 5.9 15.3 5.9 16.3 5.9 16.4 6.2 16.4 7 16.4 7 16.6 7 16.6 7 16.6 7 16.6 4.4 16.6 4.4 16.6 4.4 16.4 4.4 16.4 4.4 16.4 5.2 16.3 5.5 15.3 5.5 15.3 5.5 14.4 5.5 14.4 5.5 14.4 5.5 14.4 3.2 14.4 3.2 14.4 2.8 14.4 2.8 14.9 2.8 14.9 2.8 16.2 2.8 16.2 2.8 17.7 2.8 18 3.3 18.1 4.7 18.1 4.7 18.4 4.7 18.4 4.7 18.4 4.7 18.1 2.5 18.1 2.5 18.1 2.5 12.5 2.5 12.5 2.5 12.5 2.5 12.5 2.8 12.5 2.8 12.5 2.8 12.7 2.8 12.7 2.8 13.5 2.8 13.5 2.9 13.5 3.2 13.5 3.2 13.5 8.4 13.5 8.4 13.5 8.8 13.5 8.9 12.7 8.9 12.7 8.9 12.5 8.9 12.5 8.9 12.5 8.9 12.5 9.2 12.5 9.2 12.5 9.2 18.2 9.2 18.2 9.2 18.2 9.2 18.7 6.7 18.7 6.7z"/><path d="M21.7 3.1C21.7 3.1 23 1.1 23 1.1 23.3 0.8 23.6 0.5 24.5 0.5 24.5 0.5 24.5 0.2 24.5 0.2 24.5 0.2 22.1 0.2 22.1 0.2 22.1 0.2 22.1 0.5 22.1 0.5 22.5 0.5 22.7 0.7 22.7 0.9 22.7 1 22.7 1.1 22.6 1.2 22.6 1.2 21.5 2.8 21.5 2.8 21.5 2.8 20.2 0.9 20.2 0.9 20.2 0.9 20.1 0.8 20.1 0.8 20.1 0.7 20.4 0.5 20.8 0.5 20.8 0.5 20.8 0.2 20.8 0.2 20.4 0.2 19.7 0.2 19.3 0.2 19 0.2 18.4 0.2 18 0.2 18 0.2 18 0.5 18 0.5 18 0.5 18.2 0.5 18.2 0.5 18.8 0.5 19 0.5 19.2 0.8 19.2 0.8 21 3.6 21 3.6 21 3.6 19.4 6 19.4 6 19.2 6.2 18.9 6.7 17.9 6.7 17.9 6.7 17.9 7 17.9 7 17.9 7 20.3 7 20.3 7 20.3 7 20.3 6.7 20.3 6.7 19.8 6.7 19.7 6.4 19.7 6.2 19.7 6.1 19.7 6.1 19.8 6 19.8 6 21.2 3.9 21.2 3.9 21.2 3.9 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.3 22.8 6.4 22.8 6.5 22.6 6.7 22.2 6.7 22.2 6.7 22.2 7 22.2 7 22.5 6.9 23.2 6.9 23.6 6.9 24 6.9 24.5 7 24.9 7 24.9 7 24.9 6.7 24.9 6.7 24.9 6.7 24.7 6.7 24.7 6.7 24.2 6.7 24 6.6 23.8 6.3 23.8 6.3 21.7 3.1 21.7 3.1z"/></g></svg> math...
    </div>
</div>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2017 Anthony Zhang.
</div>
</body>
</html>
